{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c9c697e-0235-47b5-b48b-393f25ca13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import math \n",
    "import gmpy as g\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tf\n",
    "import torchvision.models as models\n",
    "from torchmetrics.classification import Accuracy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import skimage.filters as sk_filters\n",
    "from scipy.spatial import distance_matrix, minkowski_distance, distance\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import copy\n",
    "import logging\n",
    "\n",
    "from source_code import *\n",
    "from module_train_utility import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed28bc6c-c469-430f-bf5d-a10d563d109e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d04c4562-5375-4f18-a37d-a4010797a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!set PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a97a0dc-af25-4033-9705-30b8ef17c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae8b1925-264c-40be-bad4-ad581884c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_load import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10866d75-999e-4bba-8eb9-1f9baf6294ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creading Models\n",
    "'''\n",
    "#device\n",
    "device=(\n",
    "    'cuda'\n",
    "    if torch.cuda.is_available()\n",
    "    #else 'mps'\n",
    "    #if torch.mps.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "print(f'using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1b019-fff6-4442-bc5c-b4aa4560027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'your_image_dir/'\n",
    "names=[file for file in os.listdir(img_dir) if file.endswith('.png')]\n",
    "names = [os.path.splitext(name)[0] for name in names]\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc66f631-d3a5-4a49-8c7a-3dcbb00e27fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PatchClassifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2956593f-0f56-4d32-9062-3d9f6917e31a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define model\n",
    "model = PatchClassifier(fig_size=128,\n",
    "                       dropout=0.2,\n",
    "                       n_pos=135,\n",
    "                       kernel_size=4,\n",
    "                       patch_size=8,\n",
    "                       num_class=4,\n",
    "                       depth1=2,\n",
    "                       depth2=8,\n",
    "                       depth3=4,\n",
    "                       heads=16,\n",
    "                       channel=32,\n",
    "                       policy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4788a90-455a-407d-a1d0-53ca9ea77020",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/your_out_dir/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f2d6d4-ca7f-442a-8abc-60b469f19e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('train_model_weights.pth')) \n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "295916ff-7027-48c3-8e9a-dc3705e8287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tiling image: 100%|██████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n",
      "/home/zxun/.conda/envs/TLS/lib/python3.10/site-packages/torch/nn/modules/conv.py:549: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1036.)\n",
      "  return F.conv2d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: A503; score: {np.int64(0), np.int64(1), np.int64(2)}\n",
      "A503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tiling image: 100%|██████████████████████████████████████████████████████████████████ [ time left: 00:00 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: A502; score: {np.int64(0), np.int64(1), np.int64(2)}\n",
      "A502\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    mylist = []\n",
    "    mylist.append(name)\n",
    "    \n",
    "\n",
    "    test_dataset = test_load(adj=True,crops=128,neighs=8,prune='Grid',names=mylist)\n",
    "    meta_filter = test_dataset.meta_filter_dict[name]\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset,batch_size=1,num_workers=2,shuffle=True)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (patches,position,_,adj) in enumerate(test_dataloader):\n",
    "            patches,position,adj = patches.to(device),position.to(device),adj.to(device)\n",
    "            \n",
    "            preds=model(patches,position,adj)\n",
    "            _,probs=torch.max(preds,1)\n",
    "            \n",
    "            position = pd.DataFrame(position.squeeze(0).cpu())\n",
    "            position=position.rename(columns={0:'coord_x',1:'coord_y'})\n",
    "            position['TLS_score'] = probs.cpu().numpy()\n",
    "            print(f'name: {name}; score: {set(probs.cpu().numpy())}')\n",
    "\n",
    "            os.mkdir(f'run_scRNAseq3/P22/{name}')\n",
    "            position.to_csv(f'run_scRNAseq3/P22/{name}/position.csv')\n",
    "    #else:\n",
    "    print(name)\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TLS",
   "language": "python",
   "name": "tls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
